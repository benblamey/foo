{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2018 Google LLC. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Basic nonlinear transform coder for RGB images.\n",
    "\n",
    "This is a close approximation of the image compression model published in:\n",
    "J. Ball√©, V. Laparra, E.P. Simoncelli (2017):\n",
    "\"End-to-end Optimized Image Compression\"\n",
    "Int. Conf. on Learning Representations (ICLR), 2017\n",
    "https://arxiv.org/abs/1611.01704\n",
    "\n",
    "With patches from Victor Xing <victor.t.xing@gmail.com>\n",
    "\n",
    "This is meant as 'educational' code - you can use this to get started with your\n",
    "own experiments. To reproduce the exact results from the paper, tuning of hyper-\n",
    "parameters may be necessary. To compress images with published models, see\n",
    "`tfci.py`.\n",
    "\n",
    "This script requires TFC v2 (`pip install tensorflow-compression==2.*`).\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import sys\n",
    "from absl import app\n",
    "from absl.flags import argparse_flags\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_compression as tfc\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "# for cellprofiler\n",
    "import cellprofiler_core.pipeline\n",
    "import cellprofiler_core.preferences\n",
    "import cellprofiler_core.utilities.java\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "\n",
    "def read_png(filename):\n",
    "    \"\"\"Loads a PNG image file.\"\"\"\n",
    "    string = tf.io.read_file(filename)\n",
    "    return tf.image.decode_image(string, channels=3)\n",
    "\n",
    "\n",
    "def write_png(filename, image):\n",
    "    \"\"\"Saves an image to a PNG file.\"\"\"\n",
    "    string = tf.image.encode_png(image)\n",
    "    tf.io.write_file(filename, string)\n",
    "\n",
    "\n",
    "class AnalysisTransform(tf.keras.Sequential):\n",
    "    \"\"\"The analysis transform.\"\"\"\n",
    "\n",
    "    def __init__(self, num_filters):\n",
    "        super().__init__(name=\"analysis\")\n",
    "        self.add(tf.keras.layers.Lambda(lambda x: x / 255.))\n",
    "        self.add(tfc.SignalConv2D(\n",
    "            num_filters, (9, 9), name=\"layer_0\", corr=True, strides_down=4,\n",
    "            padding=\"same_zeros\", use_bias=True,\n",
    "            activation=tfc.GDN(name=\"gdn_0\")))\n",
    "        self.add(tfc.SignalConv2D(\n",
    "            num_filters, (5, 5), name=\"layer_1\", corr=True, strides_down=2,\n",
    "            padding=\"same_zeros\", use_bias=True,\n",
    "            activation=tfc.GDN(name=\"gdn_1\")))\n",
    "        self.add(tfc.SignalConv2D(\n",
    "            num_filters, (5, 5), name=\"layer_2\", corr=True, strides_down=2,\n",
    "            padding=\"same_zeros\", use_bias=False,\n",
    "            activation=None))\n",
    "\n",
    "\n",
    "class SynthesisTransform(tf.keras.Sequential):\n",
    "    \"\"\"The synthesis transform.\"\"\"\n",
    "\n",
    "    def __init__(self, num_filters):\n",
    "        super().__init__(name=\"synthesis\")\n",
    "        self.add(tfc.SignalConv2D(\n",
    "            num_filters, (5, 5), name=\"layer_0\", corr=False, strides_up=2,\n",
    "            padding=\"same_zeros\", use_bias=True,\n",
    "            activation=tfc.GDN(name=\"igdn_0\", inverse=True)))\n",
    "        self.add(tfc.SignalConv2D(\n",
    "            num_filters, (5, 5), name=\"layer_1\", corr=False, strides_up=2,\n",
    "            padding=\"same_zeros\", use_bias=True,\n",
    "            activation=tfc.GDN(name=\"igdn_1\", inverse=True)))\n",
    "        self.add(tfc.SignalConv2D(\n",
    "            3, (9, 9), name=\"layer_2\", corr=False, strides_up=4,\n",
    "            padding=\"same_zeros\", use_bias=True,\n",
    "            activation=None))\n",
    "        self.add(tf.keras.layers.Lambda(lambda x: x * 255.))\n",
    "\n",
    "\n",
    "class BLS2017Model(tf.keras.Model):\n",
    "    \"\"\"Main model class.\"\"\"\n",
    "\n",
    "    # count = 0\n",
    "\n",
    "    def __init__(self, lmbda, num_filters):\n",
    "        super().__init__()\n",
    "        self.lmbda = lmbda\n",
    "        self.analysis_transform = AnalysisTransform(num_filters)\n",
    "        self.synthesis_transform = SynthesisTransform(num_filters)\n",
    "        self.prior = tfc.NoisyDeepFactorized(batch_shape=(num_filters,))\n",
    "        self.build((None, None, None, 3))\n",
    "        # self.count = count\n",
    "        # tf.print(self.count)\n",
    "\n",
    "    def call(self, x, training):\n",
    "        \"\"\"Computes rate and distortion losses.\"\"\"\n",
    "        entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
    "            self.prior, coding_rank=3, compression=False)\n",
    "\n",
    "        x = tf.cast(x, self.compute_dtype)  # TODO(jonycgn): Why is this necessary?\n",
    "        y = self.analysis_transform(x)\n",
    "        y_hat, bits = entropy_model(y, training=training)\n",
    "        x_hat = self.synthesis_transform(y_hat)\n",
    "\n",
    "        for i in range(8):\n",
    "            # tf.print('saving')\n",
    "            write_png('image/original_{}.png'.format(i), tf.dtypes.cast(x[i, :, :, :], tf.uint8))\n",
    "            write_png('image/decoded_{}.png'.format(i), tf.saturate_cast(tf.round(x_hat[i, :, :, :]), tf.uint8))\n",
    "\n",
    "        # Cellprofiler feature loss\n",
    "        cellprofiler_core.preferences.set_headless()\n",
    "        cellprofiler_core.utilities.java.start_java()\n",
    "        # os.makedirs('cp/image', exist_ok=True)\n",
    "        cp_output = 'output'\n",
    "        os.makedirs(cp_output, exist_ok=True)\n",
    "\n",
    "        pipeline = cellprofiler_core.pipeline.Pipeline()\n",
    "        pipeline.load(\"ExampleNeighbors.cppipe\")\n",
    "        cellprofiler_core.preferences.set_default_output_directory(cp_output)\n",
    "        file_list = list(pathlib.Path('.').absolute().glob('image/*.png'))\n",
    "        files = [file.as_uri() for file in file_list]\n",
    "        if len(files) > 0:\n",
    "            pipeline.read_file_list(files)\n",
    "            output_measurements = pipeline.run()\n",
    "            cp_df = pd.read_csv(\"output/Image.csv\")\n",
    "            cp_df_sim = cp_df.filter(regex='^Count|^Mean|URL_Original', axis=1)\n",
    "            # tf.print('running here')\n",
    "\n",
    "            # cellprofiler feature similarity\n",
    "            res = []\n",
    "            for i in range(8):\n",
    "                decoded_num = cp_df_sim.loc[i, 'URL_Original'].replace('.', '_').split('_')[-2]\n",
    "                original_num = cp_df_sim.loc[i + 8, 'URL_Original'].replace('.', '_').split('_')[-2]\n",
    "                if decoded_num == original_num:\n",
    "                    res.append(cosine_similarity([cp_df_sim.iloc[i, :-1]], [cp_df_sim.iloc[i + 8, :-1]])[0][0])\n",
    "                else:\n",
    "                    print('the original and decoded image numbers for similarity calculation should match.')\n",
    "\n",
    "            sim = tf.reduce_mean(res)\n",
    "            # tf.print('running here')\n",
    "            # tf.print(sim)\n",
    "\n",
    "            # tf.print(files)\n",
    "        # cellprofiler_core.utilities.java.stop_java()\n",
    "\n",
    "        # Total number of bits divided by total number of pixels.\n",
    "        num_pixels = tf.cast(tf.reduce_prod(tf.shape(x)[:-1]), bits.dtype)\n",
    "        bpp = tf.reduce_sum(bits) / num_pixels\n",
    "        # Mean squared error across pixels.\n",
    "        mse = tf.reduce_mean(tf.math.squared_difference(x, x_hat))\n",
    "        mse = tf.cast(mse, bpp.dtype)\n",
    "        sim = tf.cast(sim, bpp.dtype)\n",
    "\n",
    "        # The rate-distortion Lagrangian.\n",
    "        loss = bpp + self.lmbda * mse - sim\n",
    "\n",
    "        # tf.print(x.shape)\n",
    "        # # global count\n",
    "        # # print('Count: ' + str(count))\n",
    "        # # count = count + 1\n",
    "        # tf.print(x_hat.shape)\n",
    "        # tf.print('running here')\n",
    "\n",
    "        # tf.print('Count: ' + str(self.lmbda))\n",
    "        # tf.print('Count: ' + str(self.count))\n",
    "        # self.count += 1\n",
    "\n",
    "        return loss, bpp, mse, sim\n",
    "\n",
    "\n",
    "# @tf.autograph.experimental.do_not_convert\n",
    "def train_step(self, x):\n",
    "    # _, _, _, x_hat = self(x)\n",
    "\n",
    "    #     for i in range(8):\n",
    "    #         write_png('cp/image/original_{}.png'.format(i), tf.dtypes.cast(x[i, :, :, :], tf.uint8))\n",
    "    #         write_png('cp/image/decoded_{}.png'.format(i), tf.saturate_cast(tf.round(x_hat[i, :, :, :]), tf.uint8))\n",
    "\n",
    "    #     # Cellprofiler feature loss\n",
    "    #     cellprofiler_core.preferences.set_headless()\n",
    "    #     cellprofiler_core.utilities.java.start_java()\n",
    "    #     # os.makedirs('cp/image', exist_ok=True)\n",
    "    #     cp_output = 'cp/output'\n",
    "    #     os.makedirs(cp_output, exist_ok=True)\n",
    "\n",
    "    #     pipeline = cellprofiler_core.pipeline.Pipeline()\n",
    "    #     pipeline.load(\"cp/ExampleNeighbors.cppipe\")\n",
    "    #     cellprofiler_core.preferences.set_default_output_directory(cp_output)\n",
    "    #     file_list = list(pathlib.Path('.').absolute().glob('cp/image/*.png'))\n",
    "    #     files = [file.as_uri() for file in file_list]\n",
    "    #     if len(files) > 0:\n",
    "    #         pipeline.read_file_list(files)\n",
    "    #         tf.print(files)\n",
    "    #         output_measurements = pipeline.run()\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, bpp, mse, sim = self(x, training=True)\n",
    "    variables = self.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "    self.loss.update_state(loss)\n",
    "    self.bpp.update_state(bpp)\n",
    "    self.mse.update_state(mse)\n",
    "    self.sim.update_state(sim)\n",
    "    return {m.name: m.result() for m in [self.loss, self.bpp, self.mse, self.sim]}\n",
    "\n",
    "\n",
    "def test_step(self, x):\n",
    "    loss, bpp, mse, sim = self(x, training=False)\n",
    "    self.loss.update_state(loss)\n",
    "    self.bpp.update_state(bpp)\n",
    "    self.mse.update_state(mse)\n",
    "    self.sim.update_state(sim)\n",
    "    return {m.name: m.result() for m in [self.loss, self.bpp, self.mse, self.sim]}\n",
    "\n",
    "\n",
    "def predict_step(self, x):\n",
    "    raise NotImplementedError(\"Prediction API is not supported.\")\n",
    "\n",
    "\n",
    "def compile(self, **kwargs):\n",
    "    super().compile(\n",
    "        loss=None,\n",
    "        metrics=None,\n",
    "        loss_weights=None,\n",
    "        weighted_metrics=None,\n",
    "        **kwargs,\n",
    "    )\n",
    "    self.loss = tf.keras.metrics.Mean(name=\"loss\")\n",
    "    self.bpp = tf.keras.metrics.Mean(name=\"bpp\")\n",
    "    self.mse = tf.keras.metrics.Mean(name=\"mse\")\n",
    "    self.sim = tf.keras.metrics.Mean(name=\"sim\")\n",
    "\n",
    "\n",
    "def fit(self, *args, **kwargs):\n",
    "    # global count\n",
    "    # print('Count: ' + str(count))\n",
    "    # count = count + 1\n",
    "    retval = super().fit(*args, **kwargs)\n",
    "    # After training, fix range coding tables.\n",
    "    self.entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
    "        self.prior, coding_rank=3, compression=True)\n",
    "    return retval\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec(shape=(None, None, 3), dtype=tf.uint8),\n",
    "])\n",
    "def compress(self, x):\n",
    "    \"\"\"Compresses an image.\"\"\"\n",
    "    # Add batch dimension and cast to float.\n",
    "    x = tf.expand_dims(x, 0)\n",
    "    x = tf.cast(x, dtype=self.compute_dtype)\n",
    "    y = self.analysis_transform(x)\n",
    "    # Preserve spatial shapes of both image and latents.\n",
    "    x_shape = tf.shape(x)[1:-1]\n",
    "    y_shape = tf.shape(y)[1:-1]\n",
    "    return self.entropy_model.compress(y), x_shape, y_shape\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec(shape=(1,), dtype=tf.string),\n",
    "    tf.TensorSpec(shape=(2,), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(2,), dtype=tf.int32),\n",
    "])\n",
    "def decompress(self, string, x_shape, y_shape):\n",
    "    \"\"\"Decompresses an image.\"\"\"\n",
    "    y_hat = self.entropy_model.decompress(string, y_shape)\n",
    "    x_hat = self.synthesis_transform(y_hat)\n",
    "    # Remove batch dimension, and crop away any extraneous padding.\n",
    "    x_hat = x_hat[0, :x_shape[0], :x_shape[1], :]\n",
    "    # Then cast back to 8-bit integer.\n",
    "    return tf.saturate_cast(tf.round(x_hat), tf.uint8)\n",
    "\n",
    "\n",
    "def check_image_size(image, patchsize):\n",
    "    shape = tf.shape(image)\n",
    "    return shape[0] >= patchsize and shape[1] >= patchsize and shape[-1] == 3\n",
    "\n",
    "\n",
    "def crop_image(image, patchsize):\n",
    "    image = tf.image.random_crop(image, (patchsize, patchsize, 3))\n",
    "    return tf.cast(image, tf.keras.mixed_precision.global_policy().compute_dtype)\n",
    "\n",
    "\n",
    "def get_dataset(name, split, args):\n",
    "    \"\"\"Creates input data pipeline from a TF Datasets dataset.\"\"\"\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        dataset = tfds.load(name, split=split, shuffle_files=True)\n",
    "        if split == \"train\":\n",
    "            dataset = dataset.repeat()\n",
    "        dataset = dataset.filter(\n",
    "            lambda x: check_image_size(x[\"image\"], args.patchsize))\n",
    "        dataset = dataset.map(\n",
    "            lambda x: crop_image(x[\"image\"], args.patchsize))\n",
    "        dataset = dataset.batch(args.batchsize, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_custom_dataset(split, args):\n",
    "    \"\"\"Creates input data pipeline from custom PNG images.\"\"\"\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        files = glob.glob(args.train_glob)\n",
    "        if not files:\n",
    "            raise RuntimeError(f\"No training images found with glob \"\n",
    "                               f\"'{args.train_glob}'.\")\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(files)\n",
    "        dataset = dataset.shuffle(len(files), reshuffle_each_iteration=True)\n",
    "        if split == \"train\":\n",
    "            dataset = dataset.repeat()\n",
    "        dataset = dataset.map(\n",
    "            lambda x: crop_image(read_png(x), args.patchsize),\n",
    "            num_parallel_calls=args.preprocess_threads)\n",
    "        dataset = dataset.batch(args.batchsize, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "csv_log = CSVLogger(\"results.csv\")\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    \"\"\"Instantiates and trains the model.\"\"\"\n",
    "    if args.precision_policy:\n",
    "        tf.keras.mixed_precision.set_global_policy(args.precision_policy)\n",
    "    if args.check_numerics:\n",
    "        tf.debugging.enable_check_numerics()\n",
    "\n",
    "    model = BLS2017Model(args.lmbda, args.num_filters)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    )\n",
    "\n",
    "    if args.train_glob:\n",
    "        train_dataset = get_custom_dataset(\"train\", args)\n",
    "        validation_dataset = get_custom_dataset(\"validation\", args)\n",
    "    else:\n",
    "        train_dataset = get_dataset(\"clic\", \"train\", args)\n",
    "        validation_dataset = get_dataset(\"clic\", \"validation\", args)\n",
    "    validation_dataset = validation_dataset.take(args.max_validation_steps)\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset.prefetch(8),\n",
    "        epochs=args.epochs,\n",
    "        steps_per_epoch=args.steps_per_epoch,\n",
    "        validation_data=validation_dataset.cache(),\n",
    "        validation_freq=1,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.TerminateOnNaN(),\n",
    "            tf.keras.callbacks.TensorBoard(\n",
    "                log_dir=args.train_path,\n",
    "                histogram_freq=1, update_freq=\"epoch\"),\n",
    "            tf.keras.callbacks.BackupAndRestore(args.train_path),\n",
    "            csv_log\n",
    "        ],\n",
    "        verbose=int(args.verbose),\n",
    "    )\n",
    "    model.save(args.model_path)\n",
    "\n",
    "\n",
    "def compress(args):\n",
    "    \"\"\"Compresses an image.\"\"\"\n",
    "    # Load model and use it to compress the image.\n",
    "    model = tf.keras.models.load_model(args.model_path)\n",
    "    x = read_png(args.input_file)\n",
    "    tensors = model.compress(x)\n",
    "\n",
    "    # Write a binary file with the shape information and the compressed string.\n",
    "    packed = tfc.PackedTensors()\n",
    "    packed.pack(tensors)\n",
    "    with open(args.output_file, \"wb\") as f:\n",
    "        f.write(packed.string)\n",
    "\n",
    "    # If requested, decompress the image and measure performance.\n",
    "    if args.verbose:\n",
    "        x_hat = model.decompress(*tensors)\n",
    "\n",
    "        # Cast to float in order to compute metrics.\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x_hat = tf.cast(x_hat, tf.float32)\n",
    "        mse = tf.reduce_mean(tf.math.squared_difference(x, x_hat))\n",
    "        psnr = tf.squeeze(tf.image.psnr(x, x_hat, 255))\n",
    "        msssim = tf.squeeze(tf.image.ssim_multiscale(x, x_hat, 255))\n",
    "        msssim_db = -10. * tf.math.log(1 - msssim) / tf.math.log(10.)\n",
    "\n",
    "        # The actual bits per pixel including entropy coding overhead.\n",
    "        num_pixels = tf.reduce_prod(tf.shape(x)[:-1])\n",
    "        bpp = len(packed.string) * 8 / num_pixels\n",
    "\n",
    "        print(f\"Mean squared error: {mse:0.4f}\")\n",
    "        print(f\"PSNR (dB): {psnr:0.2f}\")\n",
    "        print(f\"Multiscale SSIM: {msssim:0.4f}\")\n",
    "        print(f\"Multiscale SSIM (dB): {msssim_db:0.2f}\")\n",
    "        print(f\"Bits per pixel: {bpp:0.4f}\")\n",
    "\n",
    "\n",
    "def decompress(args):\n",
    "    \"\"\"Decompresses an image.\"\"\"\n",
    "    # Load the model and determine the dtypes of tensors required to decompress.\n",
    "    model = tf.keras.models.load_model(args.model_path)\n",
    "    dtypes = [t.dtype for t in model.decompress.input_signature]\n",
    "\n",
    "    # Read the shape information and compressed string from the binary file,\n",
    "    # and decompress the image using the model.\n",
    "    with open(args.input_file, \"rb\") as f:\n",
    "        packed = tfc.PackedTensors(f.read())\n",
    "    tensors = packed.unpack(dtypes)\n",
    "    x_hat = model.decompress(*tensors)\n",
    "\n",
    "    # Write reconstructed image out as a PNG file.\n",
    "    write_png(args.output_file, x_hat)\n",
    "\n",
    "\n",
    "def parse_args(argv):\n",
    "    argv = ['-V', 'train',\n",
    "            '--train_glob', '/data/bbbc021-png-BLS2017-train/*.png',\n",
    "            '--train_path', '/home/jovyan/BLS2017-implementation/train-bls2017-sim',\n",
    "            '--epochs', '10']\n",
    "\n",
    "    \"\"\"Parses command line arguments.\"\"\"\n",
    "    parser = argparse_flags.ArgumentParser(\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "    # High-level options.\n",
    "    parser.add_argument(\n",
    "        \"--verbose\", \"-V\", action=\"store_true\",\n",
    "        help=\"Report progress and metrics when training or compressing.\")\n",
    "    parser.add_argument(\n",
    "        \"--model_path\", default=\"bls2017\",\n",
    "        help=\"Path where to save/load the trained model.\")\n",
    "    subparsers = parser.add_subparsers(\n",
    "        title=\"commands\", dest=\"command\",\n",
    "        help=\"What to do: 'train' loads training data and trains (or continues \"\n",
    "             \"to train) a new model. 'compress' reads an image file (lossless \"\n",
    "             \"PNG format) and writes a compressed binary file. 'decompress' \"\n",
    "             \"reads a binary file and reconstructs the image (in PNG format). \"\n",
    "             \"input and output filenames need to be provided for the latter \"\n",
    "             \"two options. Invoke '<command> -h' for more information.\")\n",
    "\n",
    "    # 'train' subcommand.\n",
    "    train_cmd = subparsers.add_parser(\n",
    "        \"train\",\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
    "        description=\"Trains (or continues to train) a new model. Note that this \"\n",
    "                    \"model trains on a continuous stream of patches drawn from \"\n",
    "                    \"the training image dataset. An epoch is always defined as \"\n",
    "                    \"the same number of batches given by --steps_per_epoch. \"\n",
    "                    \"The purpose of validation is mostly to evaluate the \"\n",
    "                    \"rate-distortion performance of the model using actual \"\n",
    "                    \"quantization rather than the differentiable proxy loss. \"\n",
    "                    \"Note that when using custom training images, the validation \"\n",
    "                    \"set is simply a random sampling of patches from the \"\n",
    "                    \"training set.\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--lambda\", type=float, default=0.01, dest=\"lmbda\",\n",
    "        help=\"Lambda for rate-distortion tradeoff.\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--train_glob\", type=str, default=None,\n",
    "        help=\"Glob pattern identifying custom training data. This pattern must \"\n",
    "             \"expand to a list of RGB images in PNG format. If unspecified, the \"\n",
    "             \"CLIC dataset from TensorFlow Datasets is used.\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--num_filters\", type=int, default=128,\n",
    "        help=\"Number of filters per layer.\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--train_path\", default=\"/tmp/train_bls2017\",\n",
    "        help=\"Path where to log training metrics for TensorBoard and back up \"\n",
    "             \"intermediate model checkpoints.\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--c\", type=int, default=8,\n",
    "        help=\"Batch size for training and validation.\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--patchsize\", type=int, default=256,\n",
    "        help=\"Size of image patches for training and validation.\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--epochs\", type=int, default=1000,\n",
    "        help=\"Train up to this number of epochs. (One epoch is here defined as \"\n",
    "             \"the number of steps given by --steps_per_epoch, not iterations \"\n",
    "             \"over the full training dataset.)\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--steps_per_epoch\", type=int, default=1000,\n",
    "        help=\"Perform validation and produce logs after this many batches.\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--max_validation_steps\", type=int, default=16,\n",
    "        help=\"Maximum number of batches to use for validation. If -1, use one \"\n",
    "             \"patch from each image in the training set.\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--preprocess_threads\", type=int, default=16,\n",
    "        help=\"Number of CPU threads to use for parallel decoding of training \"\n",
    "             \"images.\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--precision_policy\", type=str, default=None,\n",
    "        help=\"Policy for `tf.keras.mixed_precision` training.\")\n",
    "    train_cmd.add_argument(\n",
    "        \"--check_numerics\", action=\"store_true\",\n",
    "        help=\"Enable TF support for catching NaN and Inf in tensors.\")\n",
    "\n",
    "    # 'compress' subcommand.\n",
    "    compress_cmd = subparsers.add_parser(\n",
    "        \"compress\",\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
    "        description=\"Reads a PNG file, compresses it, and writes a TFCI file.\")\n",
    "\n",
    "    # 'decompress' subcommand.\n",
    "    decompress_cmd = subparsers.add_parser(\n",
    "        \"decompress\",\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
    "        description=\"Reads a TFCI file, reconstructs the image, and writes back \"\n",
    "                    \"a PNG file.\")\n",
    "\n",
    "    # Arguments for both 'compress' and 'decompress'.\n",
    "    for cmd, ext in ((compress_cmd, \".tfci\"), (decompress_cmd, \".png\")):\n",
    "        cmd.add_argument(\n",
    "            \"input_file\",\n",
    "            help=\"Input filename.\")\n",
    "        cmd.add_argument(\n",
    "            \"output_file\", nargs=\"?\",\n",
    "            help=f\"Output filename (optional). If not provided, appends '{ext}' to \"\n",
    "                 f\"the input filename.\")\n",
    "\n",
    "    # Parse arguments.\n",
    "    # args = parser.parse_args(argv[1:])\n",
    "    args = parser.parse_args(argv)\n",
    "    if args.command is None:\n",
    "        parser.print_usage()\n",
    "        sys.exit(2)\n",
    "    return args\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # Invoke subcommand.\n",
    "    if args.command == \"train\":\n",
    "        train(args)\n",
    "    elif args.command == \"compress\":\n",
    "        if not args.output_file:\n",
    "            args.output_file = args.input_file + \".tfci\"\n",
    "        compress(args)\n",
    "    elif args.command == \"decompress\":\n",
    "        if not args.output_file:\n",
    "            args.output_file = args.input_file + \".png\"\n",
    "        decompress(args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(main, flags_parser=parse_args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}